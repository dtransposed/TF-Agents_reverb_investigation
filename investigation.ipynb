{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import reverb\n",
    "from tf_agents.environments.py_environment import PyEnvironment\n",
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
    "from tf_agents.environments.utils import validate_py_environment\n",
    "from tf_agents.specs.array_spec import BoundedArraySpec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.agents.ddpg import actor_network, critic_network\n",
    "from tf_agents.agents.td3 import td3_agent\n",
    "from tf_agents.policies import random_py_policy\n",
    "from custom_dynamic_episode_driver import DynamicEpisodeDriver # This is a custom  script, derived from\n",
    "                                                               # https://github.com/tensorflow/agents/blob/master/tf_agents/drivers/dynamic_episode_driver.py\n",
    "                                                               # Added to this \"investigation\" repository. Please take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is the script which attempts to redo \\nhttps://github.com/tensorflow/agents/blob/master/tf_agents/agents/td3/examples/v2/train_eval.py\\nwhile using dm's reverb framework to manage the experience buffer.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the script which attempts to redo \n",
    "https://github.com/tensorflow/agents/blob/master/tf_agents/agents/td3/examples/v2/train_eval.py\n",
    "while using dm's reverb framework to manage the experience buffer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Firstly, I specify a dummy TF_Agents PyEnvironment\n",
    "\"\"\"\n",
    "\n",
    "class SampleEnvironment(PyEnvironment):\n",
    "    def __init__(self):\n",
    "        self._observation_spec = self._init_observation_spec()\n",
    "        self._action_spec = self._init_action_spec()\n",
    "        self.current_step_index = 0\n",
    "        self.max_no_steps = 5\n",
    "    \n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "    \n",
    "    def _init_observation_spec(self):\n",
    "        observation_spec = BoundedArraySpec(shape=(6,), dtype=np.int32, minimum=0, maximum=10)\n",
    "        return observation_spec\n",
    "    \n",
    "    def _init_action_spec(self):\n",
    "        action_spec = BoundedArraySpec((3,), np.float32, minimum=-1.0, maximum=1.0)\n",
    "        return action_spec\n",
    "    \n",
    "    def _step(self, action):\n",
    "        observation = np.random.randint(low=0, high=10, size=(6,), dtype=np.int32)\n",
    "        reward = 1\n",
    "        if self.current_step_index < self.max_no_steps:\n",
    "            print('Transition step no.{}: {}'.format(self.current_step_index, observation.shape))\n",
    "            print('-----')\n",
    "            self.current_step_index +=1\n",
    "            return ts.transition(observation,reward=reward, discount=1.0)\n",
    "        else:\n",
    "            print('Termination step no.{}: {}'.format(self.current_step_index, observation.shape))\n",
    "            print('-----')\n",
    "            self.current_step_index = 0\n",
    "            return ts.termination(observation, reward=reward)\n",
    "        \n",
    "    def _reset(self):\n",
    "        observation = np.random.randint(low=0, high=10, size=(6,), dtype=np.int32)\n",
    "        print('Reset step: {}'.format(observation.shape))\n",
    "        print('-----')\n",
    "        return ts.restart(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset step: (6,)\n",
      "-----\n",
      "Transition step no.0: (6,)\n",
      "-----\n",
      "Transition step no.1: (6,)\n",
      "-----\n",
      "Transition step no.2: (6,)\n",
      "-----\n",
      "Transition step no.3: (6,)\n",
      "-----\n",
      "Transition step no.4: (6,)\n",
      "-----\n",
      "Termination step no.5: (6,)\n",
      "-----\n",
      "Reset step: (6,)\n",
      "-----\n",
      "Transition step no.0: (6,)\n",
      "-----\n",
      "Transition step no.1: (6,)\n",
      "-----\n",
      "Transition step no.2: (6,)\n",
      "-----\n",
      "Transition step no.3: (6,)\n",
      "-----\n",
      "Transition step no.4: (6,)\n",
      "-----\n",
      "Termination step no.5: (6,)\n",
      "-----\n",
      "Reset step: (6,)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's create PyEnvironment, derive a TFPyEnvironment from it and finally validate that the dummy environment is valid.\n",
    "\"\"\"\n",
    "py_env = SampleEnvironment()\n",
    "tf_env = TFPyEnvironment(py_env)\n",
    "validate_py_environment(py_env, episodes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a server, sampling client (to pass experience to the table) and training client (to retrieve experience from\n",
    "the table and feed it into the tf_agent.train() method.)\n",
    "\"\"\"\n",
    "dm_server= reverb.Server(\n",
    "    tables=[\n",
    "        reverb.Table(\n",
    "            name='my_table',\n",
    "            sampler=reverb.selectors.Prioritized(priority_exponent=0.8),\n",
    "            remover=reverb.selectors.Fifo(),\n",
    "            max_size=int(1e6),\n",
    "            rate_limiter=reverb.rate_limiters.MinSize(1)),\n",
    "    ],\n",
    "    # Sets the port to None to make the server pick one automatically.\n",
    "    port=None)\n",
    "\n",
    "sampling_client = reverb.Client('localhost:{}'.format(dm_server.port))\n",
    "training_client = reverb.TFClient('localhost:{}'.format(dm_server.port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining tf.agent as specified in the original train_eval.py code\n",
    "\"\"\"\n",
    "\n",
    "actor_fc_layers=(400, 300)\n",
    "critic_obs_fc_layers=(400,)\n",
    "critic_action_fc_layers=None\n",
    "critic_joint_fc_layers=(300,)\n",
    "exploration_noise_std=0.1\n",
    "target_update_tau=0.05\n",
    "target_update_period=5\n",
    "actor_update_period=2\n",
    "gradient_clipping=None\n",
    "dqda_clipping=None\n",
    "td_errors_loss_fn=tf.compat.v1.losses.huber_loss\n",
    "gamma=0.995\n",
    "reward_scale_factor=1.0\n",
    "gradient_clipping=None\n",
    "actor_learning_rate=1e-4\n",
    "critic_learning_rate=1e-3\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "actor_net = actor_network.ActorNetwork(\n",
    "    tf_env.time_step_spec().observation,\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=actor_fc_layers)\n",
    "\n",
    "critic_net_input_specs = (tf_env.time_step_spec().observation,\n",
    "                          tf_env.action_spec())\n",
    "\n",
    "critic_net = critic_network.CriticNetwork(\n",
    "    critic_net_input_specs,\n",
    "    observation_fc_layer_params=critic_obs_fc_layers,\n",
    "    action_fc_layer_params=critic_action_fc_layers,\n",
    "    joint_fc_layer_params=critic_joint_fc_layers)\n",
    "\n",
    "\n",
    "tf_agent = td3_agent.Td3Agent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    actor_network=actor_net,\n",
    "    critic_network=critic_net,\n",
    "    actor_optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=actor_learning_rate),\n",
    "    critic_optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=critic_learning_rate),\n",
    "    exploration_noise_std=exploration_noise_std,\n",
    "    target_update_tau=target_update_tau,\n",
    "    target_update_period=target_update_period,\n",
    "    actor_update_period=actor_update_period,\n",
    "    dqda_clipping=dqda_clipping,\n",
    "    td_errors_loss_fn=td_errors_loss_fn,\n",
    "    gamma=gamma,\n",
    "    reward_scale_factor=reward_scale_factor,\n",
    "    gradient_clipping=gradient_clipping,\n",
    "    train_step_counter=global_step)\n",
    "\n",
    "tf_agent.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset step: (6,)\n",
      "-----\n",
      "Transition step no.0: (6,)\n",
      "-----\n",
      "Trajectory: Trajectory(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[0, 5, 3, 1, 6, 2]], dtype=int32)>, action=array([[-0.08907502, -0.43950248,  0.12805901]], dtype=float32), policy_info=(), next_step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)\n",
      "Transition step no.1: (6,)\n",
      "-----\n",
      "Trajectory: Trajectory(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[6, 3, 9, 8, 2, 5]], dtype=int32)>, action=array([[-0.9718742 ,  0.77809495,  0.02244174]], dtype=float32), policy_info=(), next_step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)\n",
      "Transition step no.2: (6,)\n",
      "-----\n",
      "Trajectory: Trajectory(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[3, 6, 4, 4, 6, 3]], dtype=int32)>, action=array([[-0.16252926,  0.39321747,  0.8352385 ]], dtype=float32), policy_info=(), next_step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)\n",
      "Transition step no.3: (6,)\n",
      "-----\n",
      "Trajectory: Trajectory(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[7, 8, 1, 7, 7, 3]], dtype=int32)>, action=array([[-0.1816488 ,  0.12457877, -0.8158514 ]], dtype=float32), policy_info=(), next_step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)\n",
      "Transition step no.4: (6,)\n",
      "-----\n",
      "Trajectory: Trajectory(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[1, 2, 8, 0, 3, 6]], dtype=int32)>, action=array([[-0.91472346, -0.81131023,  0.9363459 ]], dtype=float32), policy_info=(), next_step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)\n",
      "Termination step no.5: (6,)\n",
      "-----\n",
      "Trajectory: Trajectory(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[2, 6, 1, 0, 1, 8]], dtype=int32)>, action=array([[-0.9520171 , -0.73782533, -0.03236499]], dtype=float32), policy_info=(), next_step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>)\n",
      "Transition step no.0: (6,)\n",
      "-----\n",
      "Trajectory: Trajectory(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[2, 0, 0, 3, 9, 3]], dtype=int32)>, action=array([[-0.85556614, -0.01928881,  0.6431682 ]], dtype=float32), policy_info=(), next_step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[0, 9, 7, 9, 9, 4]], dtype=int32)>),\n",
       " ())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_policy = random_py_policy.RandomPyPolicy(time_step_spec=py_env.time_step_spec(),\n",
    "                                                action_spec=py_env.action_spec())\n",
    "\n",
    "collect_driver = DynamicEpisodeDriver(tf_env, \n",
    "                                      random_policy,\n",
    "                                      observers=[],\n",
    "                                      sampling_client = sampling_client, # Note, that my custom driver uses sampling client\n",
    "                                      num_episodes=1)\n",
    "collect_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory(step_type=TensorShape([1]), observation=TensorShape([1, 6]), action=TensorShape([1, 3]), policy_info=(), next_step_type=TensorShape([1]), reward=TensorShape([1]), discount=TensorShape([1]))\n",
      "----\n",
      "Trajectory(step_type=tf.int32, observation=tf.int32, action=tf.float32, policy_info=(), next_step_type=tf.int32, reward=tf.float32, discount=tf.float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Error converting shapes to a TensorShape: Dimension value must be integer or None or have an __index__ method, got value 'tf.int32' with type '<class 'tensorflow.python.framework.dtypes.DType'>'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1228\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;31m# Treat as a singleton dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    199\u001b[0m                       \u001b[0;34m\"an __index__ method, got value '{0!r}' with type '{1!r}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                       .format(value, type(value))), None)\n\u001b[0m\u001b[1;32m    201\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value 'tf.int32' with type '<class 'tensorflow.python.framework.dtypes.DType'>'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-725773fee938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'my_table'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         shapes=dtypes)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/reverb/tf_client.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(self, table, dtypes, shapes, capacity, num_workers_per_iterator, max_samples_per_stream, sequence_length, emit_timesteps, rate_limiter_timeout_ms)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0memit_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memit_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         rate_limiter_timeout_ms=rate_limiter_timeout_ms)\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/reverb/tf_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, server_address, table, dtypes, shapes, max_in_flight_samples_per_worker, num_workers_per_iterator, max_samples_per_stream, sequence_length, emit_timesteps, rate_limiter_timeout_ms)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;31m# between v1 and v2 APIs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;31m# pytype: disable=wrong-arg-count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0;31m# DatasetV2 requires the dataset as a variant tensor during init.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2172\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2174\u001b[0;31m       \u001b[0mvariant_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"_as_variant_tensor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/reverb/tf_client.py\u001b[0m in \u001b[0;36m_as_variant_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mnum_workers_per_iterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers_per_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mmax_samples_per_stream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_samples_per_stream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         rate_limiter_timeout_ms=self._rate_limiter_timeout_ms)\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mreverb_dataset\u001b[0;34m(server_address, table, dtypes, shapes, sequence_length, emit_timesteps, max_in_flight_samples_per_worker, num_workers_per_iterator, max_samples_per_stream, rate_limiter_timeout_ms, name)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mreverb_dataset_eager_fallback\u001b[0;34m(server_address, table, dtypes, shapes, sequence_length, emit_timesteps, max_in_flight_samples_per_worker, num_workers_per_iterator, max_samples_per_stream, rate_limiter_timeout_ms, name, ctx)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error converting %s to a TensorShape: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n",
      "\u001b[0;31mTypeError\u001b[0m: Error converting shapes to a TensorShape: Dimension value must be integer or None or have an __index__ method, got value 'tf.int32' with type '<class 'tensorflow.python.framework.dtypes.DType'>'."
     ]
    }
   ],
   "source": [
    "sequence_length = 1\n",
    "data_spec = tf_agent.collect_data_spec # Set in the constructor of the ReverbRB\n",
    "\n",
    "# Before calling client.dataset \n",
    "get_dtype = lambda x: tf.as_dtype(x.dtype)\n",
    "get_shape = lambda x: (sequence_length,) + x.shape\n",
    "shapes = tf.nest.map_structure(get_shape, data_spec)\n",
    "dtypes = tf.nest.map_structure(get_dtype, data_spec)\n",
    "print(shapes)\n",
    "print('----')\n",
    "print(dtypes)\n",
    "\n",
    "dataset = training_client.dataset(\n",
    "        table='my_table',\n",
    "        dtypes=dtypes,\n",
    "        shapes=dtypes)\n",
    "\n",
    "print(dataset)\n",
    "#dataset = dataset.batch(128)\n",
    "\n",
    "for sample in dataset.take(1):\n",
    "    print(sample.info.key)        \n",
    "    print(sample.info.probability)\n",
    "    print(sample.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
